{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Packages**\n",
    "\n",
    "* NumPy: Numerical Python (NumPy) is the foundation package. Other packages and libraries are built on top of NumPy. \n",
    "* pandas: Provides data structures and processing capabilities similar to ones found in R and Excel. Also provides time series capabilities.\n",
    "* SciPy: Collection of packages to tackle a number of computing problems in data analytics, statistics, and linear algebra.\n",
    "* matplotlib: Plotting library. Allows to plot a number of 2D graphs and will serve as primary graphics library.\n",
    "* IPython: Interactive Python shell that allows quick prototyping of code. \n",
    "* Statsmodels: Allows data analysis, statistical model estimation, statistical tests, and regressions, and function plotting. \n",
    "* BeautifulSoup: Python library for crawling the web. Allows you to pull data from HTML and XML pages. \n",
    "* Scikits: A number of packages for running simulations, machine learning, data mining, optimization, and time series models. \n",
    "* RPy: Integrates Python with R, allows calling of R commands from Python code\n",
    "\n",
    "**IPython notebook**\n",
    "\n",
    "IPython is a software package in Python that serves as a research notebook. IPython has a seamless interface using which you can write notes as well as perform data analysis in the same file. The data analysis part allows you to write the code and run it from within the notebook itself. The results also are displayed in the notebook. Among other things, IPython provides:\n",
    "\n",
    "1. An interactive shell\n",
    "2. Notebook that is browser based. The notebook supports text, code, expressions, graphs and interactive data visualization, embed images and videos, and also links to web pages on the Internet. \n",
    "3. Tools for parallel computing.\n",
    "4. Import external code and run it.\n",
    "5. Export the notebook in a number of formats.\n",
    "\n",
    "\n",
    "\n",
    "**Creating an IPython notebook**\n",
    "\n",
    "In order to create an IPython notebook, choose File -> New -> IPython notebook. \n",
    "\n",
    "Hitting Alt-Enter creates a new cell. A cell is nothing but a placeholder where you can write some text or execute code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"An example of code execution in IPython\")\n",
    "25*543"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find help on some concept, make use of ? If you want to find a function or make use of wildcard entry, make use of followed by ? A quickref command gives you a quick reference to the most commonly used commands in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "collections.namedtuple?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.*mean*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tab is a very handy feature in Python. It gives you a list of all the functions and commands that are associated with a package (such as NumPy). For example, if you type np. and then press tab, a dropdown will come up with the list of all the functions associate with np. By using this, you do not have to rememeber the functions specifics and can just use tab completion.\n",
    "\n",
    "If you want to know the histroy of commands, make use of history command. This feature also allows you to extract code from a IPython notebook to a separate file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running external code files in IPython**\n",
    "\n",
    "If you want to run external code files in Python, make use of %run command followed by the path of the file. IPython shell will execute the code and will display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"D:\\fibonacci.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax Formalities**\n",
    "\n",
    "* Python is case sensitive\n",
    "* Python makes use of whitespace for code structuring and marking logical breaks in the code (In contrast to other programming languages that use braces)\n",
    "* End of line marks end of a statement, so does not require a semicolon at end of each statement\n",
    "* Whitespace at the beginning of the line is important. This is called indentation.\n",
    "* Leading whitespace (spaces and tabs) at the beginning of the logical line is used to determine the indentation level of the logical line.\n",
    "* Statements which go together must have the same indentation. Each such set of statements is called a block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "a =7 \n",
    "i ='text'\n",
    "print(i)\n",
    "print ('Value is ', i) # Error! Notice a single space at the start of the li\n",
    "print ('I repeat, the value is ', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments** \n",
    "\n",
    "One line comments are denoted by (#) at the start of line Multiple line comments start with ''' and end with '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a single line comment\n",
    "'''\n",
    "print(\"We are in a comment\")\n",
    "print (\"We are still in a comment\")\n",
    "'''\n",
    "print(\"We are out of the comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of indentation\n",
    "'''\n",
    "for x in alist:\n",
    "    if x < anumber:\n",
    "            print(x)\n",
    "    else:\n",
    "        print(-x)\n",
    "        \n",
    "is similar to\n",
    "\n",
    "for x in alist \n",
    "{if x < anumber  {\n",
    "        print(x)\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        print(-x)\n",
    "    }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "if x < 5:\n",
    "    print(x)\n",
    "print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 21\n",
    "y =25\n",
    "print(x)\n",
    "if x<10:\n",
    "    print(x)\n",
    "    \n",
    "    print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Variables and Data Structures**\n",
    "\n",
    "* Built-in data types: Integer, Floating point, String, Boolean Values, Date and Time\n",
    "* Additional data structures: Tuples, Lists, Dictionary\n",
    "* A variable is a name that refers to a value.\n",
    "* No need to specify type to a variable; Python automatically assigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 100          # An integer assignment\n",
    "miles   = 1000.0       # A floating point\n",
    "name    = 'Ajay'        # A string\n",
    "\n",
    "print(counter)\n",
    "print(miles)\n",
    "print(name)\n",
    "\n",
    "a = 11111\n",
    "b = 2.0\n",
    "c = \"0\"\n",
    "d = \"2\"\n",
    "print(b + a)\n",
    "print(c  + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strings**\n",
    "\n",
    "* Built-in string class named \"str\" with many handy features\n",
    "* In addition to numerical data processing, Python has very strong string processing capabilities. \n",
    "* Subsets of strings can be taken using the slice operator ( [ ] and [ : ] ) with indexes starting at 0 in the beginning of the string and working their way from -1 at the end.\n",
    "* The plus ( + ) sign is the string concatenation operator and the asterisk ( * ) is the repetition operator.\n",
    "* Strings in Python are immutable. Unlike other datasets such as lists, you cannot manipulate individual string values. In order to do so, you have to take subsets of strings and form a new string. \n",
    "* A string can be converted to a numerical type and vice versa (wherever applicable). Many a times, raw data, although numeric, is coded in string format. This feature provides a clean way to make sure all of the data is in numeric form.\n",
    "* Strings are sequence of characters and can be tokenized.\n",
    "* Strings and numbers can also be formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = 'Hello World' \n",
    "print (str)    # prints complete string\n",
    "print (str[0]) # prints first character of string\n",
    "print (str[2:5])   #prints characters starting from 3rd to 5th \n",
    "print (str[2:])    #prints string starting from 3rd character\n",
    "print (str*2)    #prints string two times\n",
    "print (str + \"TEST\")   # prints concatenated string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str =\"hello\"\n",
    "print(str[-1])\n",
    "\n",
    "a = 'this is a string'\n",
    "b = a.replace('string','longer string')\n",
    "print (a) \n",
    "print (b)\n",
    "\n",
    "a = '20.3'\n",
    "anum = int(a)\n",
    "print (anum + anum)\n",
    "\n",
    "a = \"hi\"\n",
    "anum = int(a)\n",
    "print (anum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"hi\"\n",
    "print (a)\n",
    "print (len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"This is python\"\n",
    "strlist = list(string)\n",
    "print(strlist)\n",
    "\n",
    "format = '%.2f %s is $%d'\n",
    "format %(4.5560,'Argentine Pesos',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(string)\n",
    "print (string.count('s'))\n",
    "print (string.split(' '))\n",
    "print (string.upper())\n",
    "print (string.lower())\n",
    "print (string.swapcase())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"    This is a bright, sunny day      \"\n",
    "print (str1.strip())\n",
    "print (str1.lstrip())\n",
    "print (str1.rstrip())\n",
    "print (\":\".join(str1))\n",
    "print (len(str1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school = 'ISB'\n",
    "print ('S' in school)\n",
    "'L' in school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='X-DSPAM-Confidence:   1.90323453434'\n",
    "pos = x.find(':')\n",
    "print(pos)\n",
    "num=float(x[pos+1:])\n",
    "print (num, type(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lists**\n",
    "\n",
    "* Lists, along with dictionary, are perhaps most important data types.\n",
    "* A list contains items separated by commas and enclosed within square brackets ([]).\n",
    "* All the items belonging to a list can be of different data type.\n",
    "* Lists are similar to arrays in C language.\n",
    "* The plus ( + ) sign is the list concatenation operator, and the asterisk ( * ) is the repetition operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [ 'abcd', 786 , 2.23, 'ISB', 70.2 ]\n",
    "tinylist = [123, 'ISB']\n",
    "\n",
    "print (list)          # Prints complete list\n",
    "print (list[0])       # Prints first element of the list\n",
    "print (list[1:3])     # Prints elements starting from 2nd till 3rd \n",
    "print (list[2:])      # Prints elements starting from 3rd element\n",
    "print (tinylist * 2)  # Prints list two times\n",
    "print (list + tinylist) # Prints concatenated lists\n",
    "print (len(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = [ 'abcd', 786 , 2.23, 'ISB', 70.2 ]\n",
    "blist = alist\n",
    "alist = alist*2\n",
    "print (alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['Ajay', 'Vijay', 'Ramesh']\n",
    "list.append('Sujay')         \n",
    "list.insert(0, 'NewGuy')       \n",
    "list.extend(['Guy1', 'Guy2']) \n",
    "print (list)  \n",
    "print (list.index('Guy1')) \n",
    "list.remove('Guy1')\n",
    "list.pop(1)\n",
    "print (list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = range(5)    # range is a built-in function that creates a list of integers\n",
    "print (nums)         # Prints \"[0, 1, 2, 3, 4]\"\n",
    "print (nums[2:4])    # Get a slice from index 2 to 4 (exclusive); prints \"[2, 3]\"\n",
    "print (nums[2:])     # Get a slice from index 2 to the end; prints \"[2, 3, 4]\"\n",
    "print (nums[:2])     # Get a slice from the start to index 2 (exclusive); prints \"[0, 1]\"\n",
    "print (nums[:]) # Get a slice of the whole list; prints [\"0, 1, 2, 3, 4]\"\n",
    "print (nums)\n",
    "print (nums[:-1])    # Slice indices can be negative; prints [\"0, 1, 2, 3]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting\n",
    "numberlist = [1, 5, 23, 1 ,54,2, 54,23, 54,76, 76,34,87]\n",
    "numberlist.sort()\n",
    "print(numberlist)\n",
    "print (len(numberlist))\n",
    "print (max(numberlist))\n",
    "print (min(numberlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ['abcd', 'efg', 'hijk', 'lmn']\n",
    "print (sorted(string, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can even pass your own function\n",
    "string = ['abcg', 'eff', 'hijd', 'lmi']\n",
    "\n",
    "def func1(l):\n",
    "    return l[-1]\n",
    "\n",
    "\n",
    "print (sorted(string, key=func1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary**\n",
    "\n",
    "+ One of the most important built-in data structure.\n",
    "+ Python's dictionaries are kind of hash tables.\n",
    "+ They work like associative arrays and consist of key-value pairs. \n",
    "+ A dictionary key can be almost any Python type, but are usually numbers or strings. \n",
    "+ Values, on the other hand, can be any arbitrary Python object.\n",
    "+ Dictionaries are enclosed by curly braces ( { } ) and values can be assigned and accessed using square braces ( [] )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "dict['one'] = \"This is one\"\n",
    "dict[2]     = \"This is two\"\n",
    "tinydict = {'name': 'isb','code':6734, 'dept': 'sales'}\n",
    "\n",
    "print (dict['one'])       # Prints value for 'one' key\n",
    "print (dict[2])           # Prints value for 2 key\n",
    "print (tinydict)          # Prints complete dictionary\n",
    "print (tinydict.keys())   # Prints all the keys\n",
    "print (tinydict.values()) # Prints all the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sets**\n",
    "\n",
    "A set is an unordered collection of distinct elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = {'cat', 'dog'}\n",
    "print ('cat' in animals)   # Check if an element is in a set; prints \"True\"\n",
    "print ('fish' in animals)  # prints \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.add('fish')      # Add an element to a set\n",
    "print('fish' in animals)\n",
    "print(len(animals) )      # Number of elements in a set;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.add('cat')       # Adding an element that is already in the set does nothing\n",
    "print (len(animals))       \n",
    "animals.remove('cat')    # Remove an element from a set\n",
    "print (len(animals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data type conversion**\n",
    "\n",
    "+ Data from one type can be converted into another type using conversion operators.\n",
    "+ Comes in handy when data is not coded in proper format (number coded as string, date coded as string)\n",
    "+ int(variable) - converts variable to integer \n",
    "+ str(variable) - converts variable to string \n",
    "+ float(variable) - converts variable to float (number with decimal) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Operators**\n",
    "\n",
    "+ + (plus) : Adds two objects \n",
    "+ - (minus) Gives the subtraction of one number from the other; if the first operand is absent it is assumed to be zero.\n",
    "+ * (multiply) Gives the multiplication of the two numbers or returns the string repeated that many times.\n",
    "+ ** (power) Returns x to the power of y\n",
    "+ / (divide) Divide x by y\n",
    "+ // (floor division) Returns the floor of the quotient\n",
    "+ % (modulo) Returns the remainder of the division\n",
    "+ < (less than) Returns whether x is less than y. All comparison operators return True or False. Note the capitalization of these names.\n",
    "+ > (greater than) Returns whether x is greater than y\n",
    "+ <= (less than or equal to) Returns whether x is less than or equal to y\n",
    "+ >= (greater than or equal to) Returns whether x is greater than or equal to y\n",
    "+ == (equal to) Compares if the objects are equal\n",
    "+ != (not equal to) Compares if the objects are not equal\n",
    "+ not (boolean NOT) If x is True, it returns False. If x is False, it returns True.\n",
    "+ and (boolean AND) x and y returns False if x is False, else it returns evaluation of y\n",
    "+ or (boolean OR) If x is True, it returns True, else it returns evaluation of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 6\n",
    "b = 7\n",
    "c = 42\n",
    "print (1, a == 6)\n",
    "print (2, a == 7)\n",
    "print (3, a == 6 and b == 7)\n",
    "print (4, a == 7 and b == 7)\n",
    "print (5, not a == 7 and b == 7)\n",
    "print (6, a == 7 or b == 7)\n",
    "print (7, a == 7 or b == 6)\n",
    "print (8, not (a == 7 and b == 6))\n",
    "print (9, not a == 7 and b == 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional Statements**\n",
    "\n",
    "**If-statement**\n",
    "\n",
    "The if statement is used to check a condition: if the condition is true, we run a block of statements (called the if-block), else we process another block of statements (called the else-block). The else clause is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 23\n",
    "if a >= 22:\n",
    "\n",
    "   print(\"if\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 20\n",
    "if a >= 22:\n",
    "\n",
    "   print(\"if\")\n",
    "   print(\"one more statement\")\n",
    "elif a >= 21:\n",
    "   print(\"elif\")\n",
    "else:\n",
    "   print(\"else\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing for an element in list\n",
    "list = ['Ajay', 'Vijay', 'Ramesh']\n",
    "if 'Vijay' in list:\n",
    "    print ('Found Vijay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**While-statement**\n",
    "\n",
    "The while statement allows you to repeatedly execute a block of statements as long as a condition is true. A while statement is an example of what is called a looping statement. A while statement can have an optional else clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "while (count < 9):\n",
    "   print ('The count is:', count)\n",
    "   count = count + 1\n",
    "\n",
    "print (\"End of while loop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For-statement**\n",
    "\n",
    "The for..in statement is another looping statement which iterates over a sequence of objects i.e. go through each item in a sequence. A sequence is just an ordered collection of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(1,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6,2):\n",
    "    print (i)\n",
    "#else:\n",
    "#   print \"The for loop is over\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traversing a list\n",
    "#What is the output\n",
    "numbers = [2, 3, 5]\n",
    "sum = 0\n",
    "for num in numbers:\n",
    "    sum += num  #sum = sum+num\n",
    "print (sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [2, 3, 5]\n",
    "getsum = [ i+2 for i in numbers ]\n",
    "print (getsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [2, 3, 5]\n",
    "getnum = [ i+2 for i in numbers if i<5]\n",
    "print (getnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Break statement**\n",
    "\n",
    "The break statement is used to break out of a loop statement i.e. stop the execution of a looping statement, even if the loop condition has not become False or the sequence of items has not been completely iterated over.\n",
    "\n",
    "An important note is that if you break out of a for or while loop, any corresponding loop else block is not executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "       if i == 5:\n",
    "           break\n",
    "       print (i)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**\n",
    "\n",
    "+ Functions are reusable piece of software.\n",
    "+ Block of statements that accepts some arguments, perform some functionality, and provide the output.\n",
    "+ Defined using def keyword\n",
    "+ Similar to functions in R.\n",
    "+ For example, implement code to perform two way clustering once and can be used again in the same program. \n",
    "+ We will look at functions for a number of features (Fama Mac Beth regression, two way clustering, industry code classification) in subsequent sessions. \n",
    "+ A function can take arguments.\n",
    "+ Arguments are specified within parentheses in function definition separated by commas.\n",
    "+ It is also possible to assign default values to parameters in order to make the program flexible and not behave in an unexpected manner.\n",
    "+ One of the most powerful feature of functions is that it allows you to pass any number of arguments and you do not have to worry about specifying the number when writing the function. This feature becomes extremely important when dealing with lists or input data where you do not know number of data observations before hand.\n",
    "+ Scope of variables defined inside a function is local i.e. they cannot be used outside of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sayHello():\n",
    "    print('Hello World!') # block belonging to the function\n",
    "# End of function #\n",
    "\n",
    "sayHello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMax(a, b):\n",
    "   if a > b:\n",
    "       print(a, 'is maximum')\n",
    "   elif a == b:\n",
    "       print(a, 'is equal to', b)\n",
    "   else:\n",
    "       print(b, 'is maximum')\n",
    "\n",
    "printMax(3, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def say(message, times = 1):\n",
    "   print(message * times)\n",
    "\n",
    "say('Hello')\n",
    "say('World', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(a, b=5, c=10):\n",
    "   print('a is', a, 'and b is', b, 'and c is', c)\n",
    "func(3, 7)\n",
    "func(25, c=24)\n",
    "func(c=50, a=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 50\n",
    "def func(x):\n",
    "   print('x is', x)\n",
    "   x = 2\n",
    "   print('Changed local x to', x)\n",
    "func(x)\n",
    "print('x is still', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total(initial=5, *numbers, **keywords):\n",
    "   count = initial\n",
    "   for number in numbers:\n",
    "       count += number\n",
    "   for key in keywords:\n",
    "       count += keywords[key]\n",
    "   return count\n",
    "\n",
    "print(total(10, 1, 2, 3, vegetables=50, fruits=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modules**\n",
    "\n",
    "+ Functions can be used in the same program. \n",
    "+ If you want to use function (s) in other programs, make use of modules.\n",
    "+ Modules can be imported in other programs and functions contained in those modules can be used.\n",
    "+ Simplest way to create a module is to write a .py file with functions defined in that file.\n",
    "+ Other way is to import using byte-compiled .pyc files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print (os.getcwd())\n",
    "import math\n",
    "x = -25\n",
    "print(math.fabs(x))\n",
    "print(math.factorial(abs(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mymodule\n",
    "from mymodule import * #import mymodule\n",
    "print(sayhi())\n",
    "\n",
    "\n",
    "numb = input(\"Enter a non negative number\")\n",
    "num_factorial = factorial(int(numb))\n",
    "print(num_factorial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing first program**\n",
    "\n",
    "+ Source files .py extension, and can be run from command prompt by using python filename.py (optional arguments) command. \n",
    "+ Examine name.py. \n",
    "+ First line imports modules\n",
    "+ Next line defines a main() function. We can specify command line arguments. Command line args are in sys.argv[1], sys.argv[2]\n",
    "+ sys.argv[0] is the script name itself and can be ignored\n",
    "+ name = 'main' starts the program. \n",
    "+ When a Python file is run directly, the special variable \"__name__\" is set to \"__main__\". Therefore, it's common to have the boilerplate if __name__ ==... shown above to call a main() function when the module is run directly, but not when the module is imported by some other module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run name.py\n",
    "%run \"/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/name2.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exception Handling**\n",
    "\n",
    "**Exceptions**\n",
    "\n",
    "+ An exception is an event that interrupts the ordinary sequential processing of a program.\n",
    "+ For example, what if you are going to read a file and the file does not exist? Or what if you accidentally deleted it when the program was running? Similarly, what if your program had some invalid statements? Such situations are handled using exceptions.\n",
    "\n",
    "**Handling Exceptions**\n",
    "\n",
    "+ We can handle exceptions using the try..except statement. \n",
    "+ We basically put our usual statements within the try-block and put all our error handlers in the except-block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg( numList ):\n",
    "    \"\"\"Raises TypeError or ZeroDivisionError exceptions.\"\"\"\n",
    "    sum= 0\n",
    "    for v in numList:\n",
    "        sum = sum + v\n",
    "    return float(sum)/len(numList)\n",
    "\n",
    "def avgReport(numList):\n",
    "     try:\n",
    "         m= avg(numList)\n",
    "         print (\"Average = \", m)\n",
    "     except (TypeError, ex):\n",
    "         print (\"TypeError:\", ex)\n",
    "     except (ZeroDivisionError, ex):\n",
    "         print (\"ZeroDivisionError:\", ex)\n",
    "\n",
    "                    \n",
    "list1 = [10,20,30,40]\n",
    "list2 = []\n",
    "list3 = [10,20,30,'abc']\n",
    "\n",
    "avgReport(list1)\n",
    "print(avgReport(list2))\n",
    "print(avgReport(list3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try..Finally**\n",
    "\n",
    "+ Suppose you are reading a file in your program. How do you ensure that the file object is closed properly whether or not an exception was raised? This can be done using the finally block.\n",
    "+ This final step will be performed before the try block is finished, either normally or by any exception.\n",
    "+ The finally clause is always executed. \n",
    "+ This includes all three possible cases: if the try block finishes with no exceptions; if an exception is raised and handled; and if an exception is raised but not handled. \n",
    "+ This last case means that every nested try statement with a finally clause will have that finally clause executed.\n",
    "+ Use a finally clause to close files, release locks, close database connections, write final log messages, and other kinds of final operations. \n",
    "+ In the following example, we use the finally clause to write a final log message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgReport( numList ):\n",
    "    try:\n",
    "        print (\"Start avgReport\")\n",
    "        m= avg(numList)\n",
    "        print (\"Average = \", m)\n",
    "    except TypeError, ex:\n",
    "        print (\"TypeError: \", ex)\n",
    "    except ZeroDivisionError, ex:\n",
    "        print (\"ZeroDivisionError: \", ex)\n",
    "    finally:\n",
    "         print (\"Finish avgReport\")\n",
    "\n",
    "list1 = [10,20,30,40]\n",
    "list2 = []\n",
    "list3 = [10,20,30,'abc']\n",
    "\n",
    "avgReport(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Some common built-in exceptions**\n",
    "\n",
    "exception KeyboardInterrupt\n",
    " This is raised when a user hits ctrl-C to send an interrupt signal to the Python interpreter. \n",
    "\n",
    "exception AttributeError\n",
    " Attribute not found in an object.\n",
    "\n",
    "exception EOFError\n",
    " Read beyond end of file.\n",
    "\n",
    "exception FloatingPointError\n",
    " Floating point operation failed.\n",
    "\n",
    "exception IOError\n",
    " I/O operation failed.\n",
    "\n",
    "exception IndexError\n",
    " Sequence index out of range.\n",
    "\n",
    "exception KeyError\n",
    " Mapping key not found.\n",
    "\n",
    "exception TypeError\n",
    " Inappropriate argument type.\n",
    "\n",
    "exception ValueError\n",
    " Inappropriate argument value (of correct type).\n",
    "\n",
    "exception ZeroDivisionError\n",
    " Second argument to a division or modulo operation was zero.\n",
    "\n",
    "exception MemoryError\n",
    " Out of memory.\n",
    "\n",
    "exception RuntimeError\n",
    " Unspecified run-time error.\n",
    "\n",
    "exception SystemError\n",
    " Internal error in the Python interpreter\n",
    "\n",
    "exception ImportError\n",
    " Import can’t find module, or can’t find name in module.\n",
    "\n",
    "exception IndentationError\n",
    " Improper indentation.\n",
    "\n",
    "exception NameError\n",
    " Name not found globally.\n",
    "\n",
    "exception SyntaxError\n",
    " Invalid syntax.\n",
    "\n",
    "exception UnboundLocalError\n",
    " Local name referenced but not bound to a value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classes**\n",
    "\n",
    "Python is an object oriented programming language. Almost everything in Python is an object, with its properties and methods. A Class is like an object constructor, or a \"blueprint\" for creating objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "  x = 5\n",
    "\n",
    "p1 = MyClass()\n",
    "print(p1.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example above is very simplistic in nature, and not really useful in real life applications.\n",
    "\n",
    "To understand the meaning of classes we have to understand the built-in __init__() function.\n",
    "\n",
    "All classes have a function called __init__(), which is always executed when the class is being initiated.\n",
    "\n",
    "Use the __init__() function to assign values to object properties, or other operations that are necessary to do when the object is being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "  def __init__(self, name, age):\n",
    "    self.name = name\n",
    "    self.age = age\n",
    "\n",
    "p1 = Person(\"Peeyush\", 32)\n",
    "\n",
    "print(p1.name)\n",
    "print(p1.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objects can also contain methods. Methods in objects are functions that belong to the object.\n",
    "class Greeter:\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, name):\n",
    "        self.name = name  # Create an instance variable\n",
    "\n",
    "    # Instance method\n",
    "    def greet(self, loud=False):\n",
    "        if loud:\n",
    "            print ('HELLO, %s!' % self.name.upper())\n",
    "        else:\n",
    "            print ('Hello, %s' % self.name)\n",
    "\n",
    "g = Greeter('Peeyush')  # Construct an instance of the Greeter class\n",
    "g.greet()            # Call an instance method; prints \"Hello, Fred\"\n",
    "g.greet(loud=True)   # Call an instance method; prints \"HELLO, FRED!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The self parameter is a reference to the current instance of the class, and is used to access variables that belongs to the class.\n",
    "#It does not have to be named self , you can call it whatever you like, but it has to be the first parameter of any function in the class\n",
    "\n",
    "class Person:\n",
    "  def __init__(mysillyobject, name, age):\n",
    "    mysillyobject.name = name\n",
    "    mysillyobject.age = age\n",
    "\n",
    "  def myfunc(abc):\n",
    "    print(\"Hello my name is \" + abc.name)\n",
    "\n",
    "p1 = Person(\"Peeyush\", 32)\n",
    "p1.myfunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customer(object):\n",
    "    \"\"\"A customer of ABC Bank with a checking account. Customers have the\n",
    "    following properties:\n",
    "\n",
    "    Attributes:\n",
    "        name: A string representing the customer's name.\n",
    "        balance: A float tracking the current balance of the customer's account.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, balance=0.0):\n",
    "        \"\"\"Return a Customer object whose name is *name* and starting\n",
    "        balance is *balance*.\"\"\"\n",
    "        self.name = name\n",
    "        self.balance = balance\n",
    "\n",
    "    def withdraw(self, amount):\n",
    "        \"\"\"Return the balance remaining after withdrawing *amount*\n",
    "        dollars.\"\"\"\n",
    "        if amount > self.balance:\n",
    "            raise RuntimeError('Amount greater than available balance.')\n",
    "        self.balance -= amount\n",
    "        return self.balance\n",
    "\n",
    "    def deposit(self, amount):\n",
    "        \"\"\"Return the balance remaining after depositing *amount*\n",
    "        dollars.\"\"\"\n",
    "        self.balance += amount\n",
    "        return self.balance\n",
    "    \n",
    "p1 = Customer(\"Peeyush\",200)\n",
    "p1.deposit(300)\n",
    "print(p1.balance)\n",
    "p1.withdraw(400)\n",
    "print(p1.balance)\n",
    "\n",
    "\n",
    "p2 = Customer(\"B13\",2000000)\n",
    "p2.deposit(300000)\n",
    "print(p2.balance)\n",
    "p2.withdraw(400000)\n",
    "print(p2.balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matplotlib:**\n",
    "\n",
    "-->matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy\n",
    "-->pyplot provides a convenient interface to the matplotlib object-oriented plotting library. It is modeled closely after Matlab(TM). Therefore, the majority of plotting commands in pyplot have Matlab(TM) analogs with similar arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line plot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "a = np.linspace(0,10,100)\n",
    "b = np.exp(-a)\n",
    "plt.plot(a,b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram\n",
    "from numpy.random import normal,rand\n",
    "x = normal(size=200)\n",
    "plt.hist(x,bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import normal,rand\n",
    "a = rand(100)\n",
    "b = rand(100)\n",
    "plt.scatter(a,b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pie Chart\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n = 20\n",
    "Z = np.random.uniform(0,1,n)\n",
    "plt.pie(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D Plot\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "X = np.arange(-5, 5, 0.25)\n",
    "Y = np.arange(-5, 5, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "R = np.sqrt(X**2 + Y**2)\n",
    "Z = np.sin(R)\n",
    "surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a new figure of size 8x6 points, using 100 dots per inch\n",
    "plt.figure(figsize=(8,6), dpi=80)\n",
    "\n",
    "# Create a new subplot from a grid of 1x1\n",
    "plt.subplot(111)\n",
    "\n",
    "X = np.linspace(-np.pi, np.pi, 256,endpoint=True)\n",
    "C,S = np.cos(X), np.sin(X)\n",
    "\n",
    "# Plot cosine using blue color with a continuous line of width 1 (pixels)\n",
    "plt.plot(X, C, color=\"blue\", linewidth=1.0, linestyle=\"-\")\n",
    "\n",
    "# Plot sine using green color with a continuous line of width 1 (pixels)\n",
    "plt.plot(X, S, color=\"green\", linewidth=1.0, linestyle=\"-\")\n",
    "\n",
    "# Set x limits\n",
    "plt.xlim(-4.0,4.0)\n",
    "\n",
    "# Set x ticks\n",
    "plt.xticks(np.linspace(-4,4,9,endpoint=True))\n",
    "\n",
    "# Set y limits\n",
    "plt.ylim(-1.0,1.0)\n",
    "\n",
    "# Set y ticks\n",
    "plt.yticks(np.linspace(-1,1,5,endpoint=True))\n",
    "\n",
    "# Show result on screen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON:**\n",
    "\n",
    "The json library can parse JSON from strings or files. The library parses JSON into a Python dictionary or list. It can also convert Python dictionaries or lists into JSON strings.\n",
    "\n",
    "Parsing JSON:\n",
    "Take the following string containing JSON data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = '{\"first_name\": \"Guido\", \"last_name\":\"Rossum\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be parsed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_string = '{\"first_name\": \"Guido\", \"last_name\":\"Rossum\"}'\n",
    "parsed_json = json.loads(json_string)\n",
    "print(parsed_json['first_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert the following to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'first_name': 'Guido',\n",
    "    'second_name': 'Rossum',\n",
    "    'titles': ['BDFL', 'Developer'],\n",
    "}\n",
    "\n",
    "print(json.dumps(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction to NumPy**\n",
    "\n",
    "NumPy (short form for Numerical Python) is the most fundamental package designed for scientific computing and data analysis. Most of the other packages such as pandas, statsmodels are built on top of it, and is an important package to know and learn about. At the heart of NumPy is a data structure called **ndarray**. ndarray is a basically a multi-dimensional array that is built specifically for the purpose of numerical data analysis. Python also has array capabilities, but they are more generic. The advantage of using ndarray is that processing is extremely efficient and fast. \n",
    "\n",
    "You can perform standard mathematical operations on either individual elements or complete array. The range of functions covered is linear algebra, statistical operations, and other specialized mathematical operations. For our purpose, we need to know about ndarray and the range of mathematical functions that are relevant to our research purpose. If you already know languages such as C, Fortran, then you can integrate NumPy code with code written in these languages and can pass NumPy arrays seamlessly. \n",
    "\n",
    "From an overall perspective, understanding of NumPy will help us in using pandas effectively as it is built on top of NumPy and frequently we will also be using functions of NumPy in research work.\n",
    "\n",
    "Possible application of NumPy package in research work are:\n",
    "\n",
    "+ Algorithmic operations such as sorting, grouping and set operations\n",
    "+ Performing repetitive operations on whole arrays of data without using loops\n",
    "+ Data merging and alignment operations\n",
    "+ Data indexing, filtering, and transformation on individual elements or whole arrays\n",
    "+ Data summarization and descriptive statistics\n",
    "\n",
    "**Installing NumPy**\n",
    "\n",
    "In order to check if NumPy is installed, go to Package Manager and type NumPy. You will get a list of packages with names closely matching to NumPy. For our purpose, we need to focus on package named numpy 1.xx. If the package is not installed, click on Install. \n",
    "\n",
    "**Importing NumPy**\n",
    "\n",
    "In order to be able to use NumPy, first import it using import statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above statement will import all of NumPy into your workspace. For starters its good, but if you are doing performance intensive work, then saving space is of importance. In such cases, you can import specific modules of NumPy by using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndarray The most important data structure in NumPy is an n-dimensional array object. Using ndarray, you can store large multidimensional datasets in Python. Being an array, you can perform mathematical operations on these arrays either one element at a time or on complete arrays without using loops. The way to initialize an array object is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = array((1,2,3,4,5))    #initializes an array a and assigns values to it\n",
    "b = array((10,20,30,40,50)) # initializes another array b\n",
    "print(a) \n",
    "print(b)\n",
    "print(a+b) \n",
    "print (a+5) \n",
    "print (a**2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = array(np.arange(15))   #arange function here works as a sequence or counter\n",
    "anarray = array(np.arange(1,15,2)) \n",
    "onemorearray = array(np.linspace(1,10,15)) \n",
    "print(c)\n",
    "print(anarray)\n",
    "print(onemorearray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each ndarray are associated two attributes: shape of the array, and type of the array. The shape of the array tells you about dimensionality of the array (rows and columns), and type of the array tells you about the data type contained in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array((32,45,123,756,23,2123))\n",
    "print(data.shape)\n",
    "print(data.dtype)\n",
    "print(data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [[1,2,3,4],[5,6,7,8]]\n",
    "arr2 = np.array(data2)\n",
    "print(arr2)\n",
    "arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((5,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(5) # creates a 5*5 identity matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(array([1,3,5,3,4,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas**\n",
    "\n",
    "pandas is the primary package for performing data analysis tasks in Python. pandas derives its name from panel data analysis and is the fundamental package that provides relational data structures (think Excel, SQL type) and a host of capabilities to play with those data structures. It is the most widely used package in Python for data analysis tasks, and is very good to work with cross sectional, time series, and panel data analysis. Python sits on top of NumPy and can be used with NumPy arrays and the functions in NumPy. How is pandas suited for a researcher’s needs:\n",
    "\n",
    "+ Has a tabular data structure that can hold both homogenous and heterogenous data.\n",
    "+ Very good indexing capabilities that makes data alignment and merging easy.\n",
    "+ Good time series functionality. No need to use different data structures for time series and cross sectional data. Allows for both ordered and unordered time-series data.\n",
    "+ A host of statistical functions developed around NumPy and pandas that makes a researcher’s task easy and fast.\n",
    "+ Programming is lot simpler and faster.\n",
    "+ Easily handles data manipulation and cleaning.\n",
    "+ Easy to expand and shorten data sets. Comprehensive merging, joins, and group by functionality to join multiple data sets.\n",
    "\n",
    "**Installing pandas** \n",
    "\n",
    "In order to check if pandas is installed, go to Package Manager and type pandas. By default, pandas already comes installed with a distribution of Canopy. If the package is not installed, click on Install.\n",
    "\n",
    "**Importing pandas**\n",
    "\n",
    "In order to be able to use NumPy, first import it using import statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #this will import pandas into your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  #we will be using numpy functions so import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Structures in pandas**\n",
    "\n",
    "There are two basic data structures in pandas: Series and DataFrame\n",
    "\n",
    "**Series:** It is similar to a NumPy 1-dimensional array. In addition to the values that are specified by the programmer, pandas attaches a label to each of the values. If the labels are not provided by the programmer, then pandas assigns labels ( 0 for first element, 1 for second element and so on). A benefit of assigning labels to data values is that it becomes easier to perform manipulations on the dataset as the whole dataset becomes more of a dictionary where each value is associated with a label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series([10,20,30,40])\n",
    "series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to specify custom index values rather than the default ones provided, you can do so using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2 = pd.Series([10,20,30,40,50], index=['one','two','three','four','five'])\n",
    "series2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ways of accesing elements in a Series object are similar to what we have seen in NumPy, and you can perform NumPy operations on Series data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2['three']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2[['one', 'three', 'five']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2[[0,1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2 ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2[series2>30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(series2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a dictionary, you can create a Series data structure from that dictionary. Suppose you are interested in EPS values for firms and the values come from different sources and is not clean. In that case you dont have to worry about cleaning and aligning those values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [90, 91, 92, 93, 94, 95]\n",
    "f1 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}\n",
    "firm1 = pd.Series(f1,index=years)\n",
    "firm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = {90:14,92:9, 93:13, 94:5}\n",
    "firm2 = pd.Series(f2,index=years)\n",
    "firm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = {93:10, 94:12, 95: 13}\n",
    "firm3 = pd.Series(f3,index=years)\n",
    "firm3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN stands for missing or NA values in pandas. Make use of isnull() function to find out if there are any missing values in the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(firm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key feature of Series data is structures is that you don't have to worry about data alignment. For example, if we have run a word count program on two different files and we have the following data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'finance': 10, 'earning': 5, 'debt':8}\n",
    "dict2 = {'finance' : 8, 'compensation':4, 'earning': 9}\n",
    "count1 = pd.Series(dict1)\n",
    "count2 = pd.Series(dict2)\n",
    "print(count1)\n",
    "count2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to calculate the sum of common words in combined files, then we dont have to worry about data alignment. If we want to include all words, then we can take care of NaN values and compute the sum. By default, Series data structure ignores NaN values. NaN values stand for missing data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1+count2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Frame**\n",
    "\n",
    "DataFrame is a tabular data structure in which data is laid out in rows and column format (similar to a CSV and SQL file), but it can also be used for higher dimensional data sets. The DataFrame object can contain homogenous and heterogenous values, and can be thought of as a logical extension of Series data structures. In contrast to Series, where there is one index, a DataFrame object has one index for column and one index for rows. This allows flexibility in accessing and manipulating data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'price':[95, 25, 85, 41, 78],\n",
    "                     'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],\n",
    "                     'company':['American Express', 'Cisco', 'Walt Disney','Microsoft', 'Walmart']})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a column is passed with no values, it will simply have NaN values\n",
    "\n",
    "In order to access a column, simply mention the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ix[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ix[data.ticker=='DIS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to add additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Year'] = 2014\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pricesquared'] = data.price**2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['pricesquared']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pricesquared'] = np.NaN\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sequence'] = np.arange(1,6)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = data.drop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [90, 91, 92, 93, 94, 95]\n",
    "f1 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}\n",
    "firm1 = pd.Series(f1,index=years)\n",
    "firm1\n",
    "f2 = {90:14,92:9, 93:13, 94:5}\n",
    "firm2 = pd.Series(f2,index=years)\n",
    "firm2\n",
    "f3 = {93:10, 94:12, 95: 13}\n",
    "firm3 = pd.Series(f3,index=years)\n",
    "firm3\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years)\n",
    "df1\n",
    "\n",
    "df1.Firm1 = firm1\n",
    "df1.Firm2 = firm2\n",
    "df1.Firm3 = firm3\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df1.T\n",
    "dft\n",
    "del dft[90]\n",
    "dft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass a number of data structures to DataFrame such as a ndarray, lists, dict, Series, and another DataFrame. You can also reindex to confirm to data to a new index. Reindexing is a powerful feature that allows you to access data in a number of different ways, and also to confirm data to some new time series or other index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexdf1 = df1.reindex([88,89,90,91,92,93,94,95,96,97,98])\n",
    "reindexdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years1 = [90, 91, 92, 93, 94, 95]\n",
    "f4 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}\n",
    "firm4 = pd.Series(f4,index=years)\n",
    "f5 = {90:14,91:12, 92:9, 93:13, 94:5, 95:8}\n",
    "firm5 = pd.Series(f5,index=years)\n",
    "f6 = {90:8, 91: 9, 92:9,93:10, 94:12, 95: 13}\n",
    "firm6 = pd.Series(f6,index=years)\n",
    "df2 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years1)\n",
    "df2.Firm1 = firm4\n",
    "df2.Firm2 = firm5\n",
    "df2.Firm3 = firm6\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexdf2 = df2.reindex([88,89,90,91,92,93,94,95,96,97,98], fill_value=0)\n",
    "reindexdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you have backfill (bfill) method to fill values backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexdf3 = df2.reindex([88,89,90,91,92,93,94,95,96,97,98], method='ffill')\n",
    "reindexdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexdf1.add(reindexdf3, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use NumPy functions inside DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(np.random.randn(3,3),columns=['one','two','three'])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x:x.max()-x.min()\n",
    "dataframe.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.apply(f,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x: x - np.mean(x)\n",
    "dataframe.apply(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return pd.Series([np.mean(x), x.max(), x.min()], index=['mean','max','min'])\n",
    "dataframe.apply(f,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(np.random.randn(3,3),columns=['one','two','three'])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.sort_index(by='one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.sort_index(by=['one','two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.cumsum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have non-numeric data, then applying describe function would produce statistics such as count, unique, frequency. In addition to this, you can also calculate skewness (skew), kurtosis (kurt), percent changes, difference, and other statistics.\n",
    "\n",
    "**Missing Data**\n",
    "\n",
    "pandas have a number of features to deal with missing data. We have seen an example of the case of descriptive statistics, where missing values are not taken into account while calculating the descriptive statistics. Missing data is denoted by NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [90, 91, 92, 93, 94, 95]\n",
    "f1 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}\n",
    "firm1 = pd.Series(f1,index=years)\n",
    "firm1\n",
    "f2 = {90:14,92:9, 93:13, 94:5}\n",
    "firm2 = pd.Series(f2,index=years)\n",
    "firm2\n",
    "f3 = {93:10, 94:12, 95: 13}\n",
    "firm3 = pd.Series(f3,index=years)\n",
    "firm3\n",
    "df3 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years)\n",
    "df3\n",
    "df3.Firm1 = firm1\n",
    "df3.Firm2 = firm2\n",
    "df3.Firm3 = firm3\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadeleted = firm2.dropna()\n",
    "nadeleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of DataFrame, if you use dropna, it deletes entire row by default. Another way is to drop only those rows that are all NA. If you want to drop columns, pass axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandf3 = df3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean2 = df3.dropna(how='all')\n",
    "clean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columndrop = df3.dropna(axis=1)\n",
    "columndrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholddf = df3.dropna(thresh=2)\n",
    "thresholddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna1 = df3.fillna(5)\n",
    "fillna1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna2 = df3.fillna({'Firm1':8, 'Firm2': 10, 'Firm3':14})\n",
    "fillna2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna3 = df3.fillna(method='ffill')\n",
    "fillna3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna4 = df3.fillna(method='bfill',limit=2)\n",
    "fillna4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna5 = df3.fillna(df3.mean())\n",
    "fillna5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hierarchical Indexing**\n",
    "\n",
    "Hierarchical indexing allows you to have index on an index (multiple index). It is an important feature of pandas using which you can select subsets of data and perform independent analyses on them. For example, suppose you have firm prices data and the data is indexed by firm name. On top of that, you can index firms by industry. Thus, industry becomes an index on top of firms. You can then perform analyses either on individual firm, or on group of firms in an industry, or on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data = pd.Series(np.random.randn(10),index=[['Ind1','Ind1','Ind1','Ind1','Ind2','Ind2','Ind2','Ind3','Ind3','Ind3'],\n",
    "                                              [1,2,3,4,1,2,3,1,2,3]])\n",
    "h_i_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data['Ind3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data['Ind1':'Ind3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data[['Ind1','Ind3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data.unstack().stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data.sum(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data.sum(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IO in pandas**\n",
    "\n",
    "In this section, we will focus on I/O from text files, csv, excel, and sql files as well as getting data from web such as Yahoo! Finance. Using functions in pandas, you can read data as a DataFrame object. \n",
    "\n",
    "**Reading a csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roedatacsv = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/roedata.csv')\n",
    "#roedatacsv\n",
    "roedatacsv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the file does not have a header, then you can either let pandas assign default headers or you can specify custom headers. If you want industry name to be the index of DataFrame, you can achieve that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roedatacsv = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/roedata.csv', index_col = 'Industry Name' )\n",
    "roedatacsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roedatacsv = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/roedata.csv', usecols = ['Industry Name','ROE'] )\n",
    "roedatacsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capm_dem_data = pd.read_table('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/capm_dem.dat', delimiter=' ',header = None)\n",
    "capm_dem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capm_dem_data = pd.read_table('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/capm_dem.dat', delimiter=' ',header = None)\n",
    "capm_dem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compustatdata = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/compustat.csv', index_col = ['ggroup','gvkey'] )\n",
    "compustatdata = compustatdata.sort_index(0,ascending=False)\n",
    "compustatdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_data = pd.read_table('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/crsp.output', sep='\\s+',header = None)\n",
    "crsp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading Files in Chunks**\n",
    "\n",
    "When dealing with very large files, sometimes it is handy to work with a subset of file or to work on file iteratively in smaller chunks. This can be done in pandas using chunksize and nrows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altdata = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/abcd.csv', chunksize=1000000 )\n",
    "altdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try not to run this\n",
    "altdata1 = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/abcd.csv')\n",
    "altdata1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in previous case, you did not receive a table as output. Instead you were given an object. This is called a TextParser object. This object allows you to iterate over the complete compustat file according to the chunksize you mentioned. Let us suppose we want to aggregate ebitda values of the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for chunks in altdata:\n",
    "    total += chunks['ESTIMATOR'].sum()\n",
    "    print(total)\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values**\n",
    "\n",
    "Some types of missing values are automatically identified by pandas as NaN while importing the data. Those types are NA, NULL, -1.#IND. Additionally, you can also specify a list of missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roemissing = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/roemissing.csv', na_values=['NULL',-999] )\n",
    "roemissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roemissing = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/roemissing.csv', na_values={'Number of firms':['NULL',-999],'ROE':['10000.00%']} )\n",
    "roemissing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roedata = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/roedata.csv')\n",
    "roedata.to_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/roedatawrite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roedata = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/roedata.csv')\n",
    "roedata.to_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/roedatawrite2.csv', index=False, columns=['Industry Name','ROE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_frame = pd.DataFrame({'key': range(5), \n",
    "                           'left_value': ['a', 'b', 'c', 'd', 'e']})\n",
    "right_frame = pd.DataFrame({'key': range(2, 7), \n",
    "                           'right_value': ['f', 'g', 'h', 'i', 'j']})\n",
    "print(left_frame)\n",
    "print('\\n')\n",
    "print(right_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_frame, right_frame, left_on='key', right_on = 'key', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_frame, right_frame, on='key', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_frame, right_frame, on='key', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_frame, right_frame, on='key', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([left_frame, right_frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([left_frame, right_frame], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titanic Case Study**\n",
    "\n",
    "Tragedy of Titanic is a widely known and discussed phenomenon, and innumerous stories have been told around Titanic. In this case study, we will try and shed some light on Titanic passengers with the help of official Titanic passengers data. Idea would be to try and see if we can make use of a number of variables to get some insights about survivors on Titanic and whether can we predict a passenger's survival based on other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/train.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating Missing Values\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender and survival possibility\n",
    "survived_sex = data[data['Survived']==1]['Sex'].value_counts()\n",
    "print(survived_sex)\n",
    "dead_sex = data[data['Survived']==0]['Sex'].value_counts()\n",
    "print(dead_sex)\n",
    "df = pd.DataFrame([survived_sex,dead_sex])\n",
    "df.index = ['Survived','Dead']\n",
    "df.plot(kind='bar',stacked=True, figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How about survival and age \n",
    "figure = plt.figure(figsize=(15,8))\n",
    "plt.hist([data[data['Survived']==1]['Age'],data[data['Survived']==0]['Age']], stacked=True, color = ['g','r'],\n",
    "         bins = 30,label = ['Survived','Dead'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What do you think about fare?\n",
    "figure = plt.figure(figsize=(15,8))\n",
    "plt.hist([data[data['Survived']==1]['Fare'],data[data['Survived']==0]['Fare']], stacked=True, color = ['g','r'],\n",
    "         bins = 30,label = ['Survived','Dead'])\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "ax = plt.subplot()\n",
    "ax.scatter(data[data['Survived']==1]['Age'],data[data['Survived']==1]['Fare'],c='green',s=40)\n",
    "ax.scatter(data[data['Survived']==0]['Age'],data[data['Survived']==0]['Fare'],c='red',s=40)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Fare')\n",
    "ax.legend(('survived','dead'),scatterpoints=1,loc='upper right',fontsize=15,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "ax.set_ylabel('Average fare')\n",
    "data.groupby('Pclass').mean()['Fare'].plot(kind='bar',figsize=(15,8), ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are you priors about survival and class of a passenger\n",
    "survived_embark = data[data['Survived']==1]['Embarked'].value_counts()\n",
    "dead_embark = data[data['Survived']==0]['Embarked'].value_counts()\n",
    "df = pd.DataFrame([survived_embark,dead_embark])\n",
    "df.index = ['Survived','Dead']\n",
    "df.plot(kind='bar',stacked=True, figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are you priors about survival and class of a passenger\n",
    "survived_embark = data[data['Survived']==1]['Pclass'].value_counts()\n",
    "dead_embark = data[data['Survived']==0]['Pclass'].value_counts()\n",
    "df = pd.DataFrame([survived_embark,dead_embark])\n",
    "df.index = ['Survived','Dead']\n",
    "df.plot(kind='bar',stacked=True, figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us look at both training and test dataset now\n",
    "def get_combined_data():\n",
    "    # reading train data\n",
    "    train = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/train.csv')\n",
    "    \n",
    "    # reading test data\n",
    "    test = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/test.csv')\n",
    "\n",
    "    # extracting and then removing the targets from the training data \n",
    "    targets = train.Survived\n",
    "    train.drop('Survived',1,inplace=True)\n",
    "    \n",
    "\n",
    "    # merging train data and test data for future feature engineering\n",
    "    combined = train.append(test)\n",
    "    combined.reset_index(inplace=True)\n",
    "    combined.drop('index',inplace=True,axis=1)\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_combined_data()\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us now try and get some more information\n",
    "def get_titles():\n",
    "\n",
    "    global combined\n",
    "    \n",
    "    # we extract the title from each name\n",
    "    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "    \n",
    "    # a map of more aggregated titles\n",
    "    Title_Dictionary = {\n",
    "                        \"Capt\":       \"Officer\",\n",
    "                        \"Col\":        \"Officer\",\n",
    "                        \"Major\":      \"Officer\",\n",
    "                        \"Jonkheer\":   \"Royalty\",\n",
    "                        \"Don\":        \"Royalty\",\n",
    "                        \"Sir\" :       \"Royalty\",\n",
    "                        \"Dr\":         \"Officer\",\n",
    "                        \"Rev\":        \"Officer\",\n",
    "                        \"the Countess\":\"Royalty\",\n",
    "                        \"Dona\":       \"Royalty\",\n",
    "                        \"Mme\":        \"Mrs\",\n",
    "                        \"Mlle\":       \"Miss\",\n",
    "                        \"Ms\":         \"Mrs\",\n",
    "                        \"Mr\" :        \"Mr\",\n",
    "                        \"Mrs\" :       \"Mrs\",\n",
    "                        \"Miss\" :      \"Miss\",\n",
    "                        \"Master\" :    \"Master\",\n",
    "                        \"Lady\" :      \"Royalty\"\n",
    "\n",
    "                        }\n",
    "    \n",
    "    # we map each title\n",
    "    combined['Title'] = combined.Title.map(Title_Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_titles()\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing with ages a bit more creatively\n",
    "grouped = combined.groupby(['Sex','Pclass','Title'])\n",
    "grouped.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_age():\n",
    "    \n",
    "    global combined\n",
    "    \n",
    "    # a function that fills the missing values of the Age variable\n",
    "    \n",
    "    def fillAges(row):\n",
    "        if row['Sex']=='female' and row['Pclass'] == 1:\n",
    "            if row['Title'] == 'Miss':\n",
    "                return 30\n",
    "            elif row['Title'] == 'Mrs':\n",
    "                return 45\n",
    "            elif row['Title'] == 'Officer':\n",
    "                return 49\n",
    "            elif row['Title'] == 'Royalty':\n",
    "                return 39\n",
    "\n",
    "        elif row['Sex']=='female' and row['Pclass'] == 2:\n",
    "            if row['Title'] == 'Miss':\n",
    "                return 20\n",
    "            elif row['Title'] == 'Mrs':\n",
    "                return 30\n",
    "\n",
    "        elif row['Sex']=='female' and row['Pclass'] == 3:\n",
    "            if row['Title'] == 'Miss':\n",
    "                return 18\n",
    "            elif row['Title'] == 'Mrs':\n",
    "                return 31\n",
    "\n",
    "        elif row['Sex']=='male' and row['Pclass'] == 1:\n",
    "            if row['Title'] == 'Master':\n",
    "                return 6\n",
    "            elif row['Title'] == 'Mr':\n",
    "                return 41.5\n",
    "            elif row['Title'] == 'Officer':\n",
    "                return 52\n",
    "            elif row['Title'] == 'Royalty':\n",
    "                return 40\n",
    "\n",
    "        elif row['Sex']=='male' and row['Pclass'] == 2:\n",
    "            if row['Title'] == 'Master':\n",
    "                return 2\n",
    "            elif row['Title'] == 'Mr':\n",
    "                return 30\n",
    "            elif row['Title'] == 'Officer':\n",
    "                return 41.5\n",
    "\n",
    "        elif row['Sex']=='male' and row['Pclass'] == 3:\n",
    "            if row['Title'] == 'Master':\n",
    "                return 6\n",
    "            elif row['Title'] == 'Mr':\n",
    "                return 26\n",
    "    \n",
    "    combined.Age = combined.apply(lambda r : fillAges(r) if np.isnan(r['Age']) else r['Age'], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_age()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_names():\n",
    "    \n",
    "    global combined\n",
    "    # we clean the Name variable\n",
    "    combined.drop('Name',axis=1,inplace=True)\n",
    "    \n",
    "    # encoding in dummy variable\n",
    "    titles_dummies = pd.get_dummies(combined['Title'],prefix='Title')\n",
    "    combined = pd.concat([combined,titles_dummies],axis=1)\n",
    "    \n",
    "    # removing the title variable\n",
    "    combined.drop('Title',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_names()\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fares():\n",
    "    \n",
    "    global combined\n",
    "    # there's one missing fare value - replacing it with the mean.\n",
    "    combined.Fare.fillna(combined.Fare.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_fares()\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_embarked():\n",
    "    \n",
    "    global combined\n",
    "    # two missing embarked values - filling them with the most frequent one (S)\n",
    "    combined.Embarked.fillna('S',inplace=True)\n",
    "    \n",
    "    # dummy encoding \n",
    "    embarked_dummies = pd.get_dummies(combined['Embarked'],prefix='Embarked')\n",
    "    combined = pd.concat([combined,embarked_dummies],axis=1)\n",
    "    combined.drop('Embarked',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_embarked()\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cabin():\n",
    "    \n",
    "    global combined\n",
    "    \n",
    "    # replacing missing cabins with U (for Uknown)\n",
    "    combined.Cabin.fillna('U',inplace=True)\n",
    "    \n",
    "    # mapping each Cabin value with the cabin letter\n",
    "    combined['Cabin'] = combined['Cabin'].map(lambda c : c[0])\n",
    "    \n",
    "    # dummy encoding ...\n",
    "    cabin_dummies = pd.get_dummies(combined['Cabin'],prefix='Cabin')\n",
    "    \n",
    "    combined = pd.concat([combined,cabin_dummies],axis=1)\n",
    "    \n",
    "    combined.drop('Cabin',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_cabin()\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sex():\n",
    "    \n",
    "    global combined\n",
    "    # mapping string values to numerical one \n",
    "    combined['Sex'] = combined['Sex'].map({'male':1,'female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_sex()\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pclass():\n",
    "    \n",
    "    global combined\n",
    "    # encoding into 3 categories:\n",
    "    pclass_dummies = pd.get_dummies(combined['Pclass'],prefix=\"Pclass\")\n",
    "    \n",
    "    # adding dummy variables\n",
    "    combined = pd.concat([combined,pclass_dummies],axis=1)\n",
    "    \n",
    "    # removing \"Pclass\"\n",
    "    \n",
    "    combined.drop('Pclass',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ticket():\n",
    "    \n",
    "    global combined\n",
    "    \n",
    "    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n",
    "    def cleanTicket(ticket):\n",
    "        ticket = ticket.replace('.','')\n",
    "        ticket = ticket.replace('/','')\n",
    "        ticket = ticket.split()\n",
    "        ticket = map(lambda t : t.strip() , ticket)\n",
    "        ticket = list(filter(lambda t : not t.isdigit(), ticket))\n",
    "        if len(ticket) > 0:\n",
    "            return ticket[0]\n",
    "        else: \n",
    "            return 'XXX'\n",
    "    \n",
    "\n",
    "    # Extracting dummy variables from tickets:\n",
    "\n",
    "    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n",
    "    tickets_dummies = pd.get_dummies(combined['Ticket'],prefix='Ticket')\n",
    "    combined = pd.concat([combined, tickets_dummies],axis=1)\n",
    "    combined.drop('Ticket',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_ticket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_family():\n",
    "    \n",
    "    global combined\n",
    "    # introducing a new feature : the size of families (including the passenger)\n",
    "    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1\n",
    "    \n",
    "    # introducing other features based on the family size\n",
    "    combined['Singleton'] = combined['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
    "    combined['SmallFamily'] = combined['FamilySize'].map(lambda s : 1 if 2<=s<=4 else 0)\n",
    "    combined['LargeFamily'] = combined['FamilySize'].map(lambda s : 1 if 5<=s else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_family()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_all_features():\n",
    "    \n",
    "    global combined\n",
    "    \n",
    "    features = list(combined.columns)\n",
    "    features.remove('PassengerId')\n",
    "    combined[features] = combined[features].apply(lambda x: x/x.max(), axis=0)\n",
    "    \n",
    "    print('Features scaled successfully !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_all_features()\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMDB Case Study**\n",
    "\n",
    "Techniques/questions to look at with this particular exmaple:\n",
    "\n",
    "+ How to merge datasets and different merge techniques\n",
    "+ List of movies that are rated most by users\n",
    "+ In ratings, how to address ratings sparsity problem\n",
    "+ Plot distributions\n",
    "+ Identify different age groups and technique of binning\n",
    "+ Subgrouping and unstacking\n",
    "+ Differences in ratings by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in column names for each CSV\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/u.user', sep='|', names=u_cols,\n",
    "                    encoding='latin-1')\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/u.data', sep='\\t', names=r_cols,\n",
    "                      encoding='latin-1')\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first five columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "movies = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/u.item', sep='|', names=m_cols, usecols=range(5),\n",
    "                     encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting a subset of columns\n",
    "movies[['movie_id','title']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another example of subsetting\n",
    "users[users.age<40].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[(users.age < 40) & (users.sex == 'F')].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge datasets\n",
    "movie_ratings = pd.merge(movies, ratings)\n",
    "lens = pd.merge(movie_ratings, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us answer some simple questions now. \n",
    "#Most rated movies\n",
    "most_rated = lens.groupby('title').size()\n",
    "most_rated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.title.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highest rated movies\n",
    "\n",
    "highest_ratings = lens.groupby('title').agg({'rating':[np.size,np.mean]})\n",
    "highest_ratings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_ratings.sort_values([('rating', 'mean')], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atleast_100 = highest_ratings['rating']['size'] >= 200\n",
    "highest_ratings[atleast_100].sort_values([('rating', 'mean')], ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(users.age,bins=5)\n",
    "plt.title(\"Distribution of users' ages\")\n",
    "plt.ylabel('count of users')\n",
    "plt.xlabel('age');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79']\n",
    "lens['age_group'] = pd.cut(lens.age, range(0, 81, 10), right=False, labels=labels)\n",
    "lens['age_group'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.groupby('age_group').agg({'rating': [np.size, np.mean]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_100 = lens.groupby('movie_id').size()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.set_index('movie_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_age = lens.loc[most_100.index].groupby(['title', 'age_group'])\n",
    "by_age.rating.mean().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_age.rating.mean().unstack(1).fillna(0)[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.reset_index('movie_id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = lens.pivot_table(index=['movie_id', 'title'],\n",
    "                           columns=['sex'],\n",
    "                           values='rating',\n",
    "                           fill_value=0)\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted['diff'] = pivoted.M - pivoted.F\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted.reset_index('movie_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreements = pivoted[pivoted.movie_id.isin(most_100.index)]['diff']\n",
    "disagreements.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreements.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagree = disagreements.copy()\n",
    "disagree=disagree.sort_values()\n",
    "disagree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagree.plot(kind='barh', figsize=[9, 15])\n",
    "plt.title('Male vs. Female Avg. Ratings\\n(Difference > 0 = Favored by Men)')\n",
    "plt.ylabel('Title')\n",
    "plt.xlabel('Average Rating Difference');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Twitter Case Study**\n",
    "\n",
    "Through this exercise, we will aim to\n",
    "\n",
    "+ Understand type of data we receive from Twitter\n",
    "+ How to remove columns in a data frame\n",
    "+ Prepare a dataframe with following columns: Company Name, Shorthand name, Description of company, number of tweets by each company\n",
    "+ Find out if a company manages multiple twitter accounts\n",
    "+ Find out number of original tweets in the dataset and create a dataframe\n",
    "+ Count hashtags\n",
    "+ Generate factor variables in Python\n",
    "+ Analyze reaction to tweets\n",
    "+ Perform a basic modeling\n",
    "+ Analyze time series behavior of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We first import the packages that we would need for this case study\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in data and looking at the number of rows and columns using shape \n",
    "twitter = pd.read_csv('/Users/suppi/Documents/Peeyush/CBA/B14/Pre-Term Python/twitter_data.csv', sep=',')\n",
    "twitter.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing columns we are not interested in\n",
    "twitter = twitter.drop('created_at_text',1)\n",
    "twitter = twitter.drop('tweet_id',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify unique user names that are tweeting\n",
    "twitter['from_user_screen_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twitter['from_user_screen_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "     return Series(dict(Number_of_tweets = x['content'].count(), \n",
    "                        Company=x['Company'].min(),\n",
    "                        Description=x['from_user_description'].min(),\n",
    "                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_count = twitter.groupby('from_user_screen_name').apply(f) \n",
    "print(len(company_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us see how many twitter handles each company uses\n",
    "counts = company_count.groupby('Company').size()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of tweets posted by each company. Any pattern here?\n",
    "company_count = company_count.sort_values(['Number_of_tweets'], ascending=False)\n",
    "company_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_count['Number_of_tweets'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter['created_at'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter['created_at'] = pd.to_datetime(twitter['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = twitter.set_index(['created_at'])\n",
    "twitter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "     return Series(dict(Number_of_tweets = x['content'].count(), \n",
    "                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count = twitter.groupby(twitter.index.date).apply(f)\n",
    "print(len(daily_count))\n",
    "daily_count.index.name = 'date'\n",
    "daily_count.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_plot = daily_count['Number_of_tweets'].plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_count = twitter.groupby(twitter.index.weekday).apply(f)\n",
    "print(len(weekday_count))\n",
    "weekday_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_count = twitter.groupby(twitter.index.hour).apply(f)\n",
    "print(len(hourly_count))\n",
    "hourly_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_plot = hourly_count['Number_of_tweets'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_count = twitter.groupby(twitter.index.minute).apply(f)\n",
    "print(len(minute_count))\n",
    "minute_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_count.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_count = twitter.groupby(twitter.index.second).apply(f)\n",
    "print(len(second_count))\n",
    "second_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_count.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
